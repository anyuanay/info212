{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anyuanay/info212/blob/main/INFO212_Week7_Lecture_Data_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhMAQ1ruLUxZ"
      },
      "source": [
        "# INFO 212: Data Science Programming 1\n",
        "___\n",
        "\n",
        "## Week 7: Data Cleaning and Preparation\n",
        "---\n",
        "\n",
        "**Agenda**\n",
        "- Missing values are None, numpy.nan\n",
        "- DataFrame.isnull() detects missing values\n",
        "- DataFrame.notnull() detects non-missing values\n",
        "- DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)[source]\n",
        "- DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)\n",
        "- DataFrame.transform() performs operations element-wise\n",
        "- duplicated() returns a boolean Series indicating whether each row is a duplicate\n",
        "- drop_duplicates() returns a DataFrame where the duplicated array is removed:\n",
        "- Transform data by applying function\n",
        "- data.replace([-999, -1000], np.nan): replace values\n",
        "- data.index.map(transform): rename index\n",
        "- data.rename(index=str.title, columns=str.upper): rename index and columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j03vB6CCLUxh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "81lmWObUMyIa",
        "outputId": "b1deab11-ab5e-421c-b046-2a691c60bb33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function google.colab.data_table.enable_dataframe_formatter()>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>google.colab.data_table.enable_dataframe_formatter</b><br/>def enable_dataframe_formatter()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/google/colab/data_table.py</a>Enables DataTable as the default IPython formatter for Pandas DataFrames.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 339);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfwthdUCLUxi"
      },
      "source": [
        "# Handling Missing Data\n",
        "\n",
        "Missing data occurs commonly in many data analysis applications.\n",
        "All of the descriptive statistics on pandas objects exclude missing data by default. For numeric data, pandas uses the floating-point value NaN (Not a Number) to represent missing data. We call this a sentinel value that can be easily detected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIZlAfzJLUxj"
      },
      "source": [
        "## `isnull()`: detects missing values\n",
        "```\n",
        "string_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado'])\n",
        "\n",
        "string_data.isnull()\n",
        "\n",
        "string_data.isnull().sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Run and test the above code."
      ],
      "metadata": {
        "id": "MkE58fNVX7xz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S2Mi4M1goZoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reasons for Missing Values\n",
        "\n",
        "Before we start treating the missing values, it is important to understand the various reasons for the missingness in data. Broadly speaking, there can be three possible reasons: (references: Wikipedia: https://en.wikipedia.org/wiki/Missing_data ; Flexible Imputation of Missing Data by R: https://stefvanbuuren.name/fimd/sec-MCAR.html)\n",
        "\n",
        "1. Missing Completely at Random (MCAR): The missing values on a given variable (Y) are not associated with other variables in a given data set or with the variable (Y) itself. In other words, there is no particular reason for the missing values. An example of MCAR is a weighing scale that ran out of batteries. Some of the data will be missing simply because of bad luck.\n",
        "\n",
        "2. Missing at Random (MAR): MAR occurs when the missingness is not random, but where missingness can be fully accounted for by variables where there is complete information. For example, when placed on a soft surface, a weighing scale may produce more missing values than when placed on a hard surface. Such data are thus not MCAR. If, however, we know surface type and if we can assume MCAR within the type of surface, then the data are MAR.\n",
        "\n",
        "3. Missing Not at Random (MNAR): Missingness depends on unobserved data or the value of the missing data itself. MNAR means that the probability of being missing varies for reasons that are unknown to us. For example, the weighing scale mechanism may wear out over time, producing more missing data as time progresses, but we may fail to note this."
      ],
      "metadata": {
        "id": "8vmskTfdg2vI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LusF0VInLUxm"
      },
      "source": [
        "## Dealing with Missing Data\n",
        "Missing data are often denoted by a \"na, n/a, N/a, N/A (not applicable)\" or \"Nan, NaN, NAN (not a number)\". The denomination depends on the used progamming langauge (NaN is the most common in python language for machine learning). In general, there are two approaches to handle missing data: Deletion and Imputation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deletions\n",
        "\n",
        "![](https://imgur.com/tBvdfyX.png)\n",
        "\n",
        "Deletion means to delete the missing values from a dataset. Deletions are further categorized into three types:\n",
        "\n",
        "### Pairwise Deletion\n",
        "\n",
        ">Parwise Deletion is used when values are missing completely at random i.e MCAR. During Pairwise deletion, only the missing values are deleted. All operations in pandas like mean,sum etc intrinsically skip missing values.\n",
        "\n",
        "### Listwise Deletion/ Dropping rows\n",
        "\n",
        ">During Listwise deletion, complete rows (which contain the missing values) are deleted. As a result, it is also called Complete Case deletion. Like Pairwise deletion, listwise deletions are also only used for MCAR values.\n",
        "\n",
        "### Dropping complete columns\n",
        "\n",
        ">If a column contains a lot of missing values, say more than 80%, and the feature is not significant, you might want to delete that feature. However, again, it is not a good methodology to delete data."
      ],
      "metadata": {
        "id": "3BFzP1XTl8cK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2pfAZVDLUxn"
      },
      "source": [
        "  \n",
        "## `dropna()`: Drops missing values; for Series, it returns non-null data.\n",
        "\n",
        "```\n",
        "from numpy import nan as NA\n",
        "data = pd.Series([1, NA, 3.5, NA, 7])\n",
        "\n",
        "data.dropna()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Run and test the above code."
      ],
      "metadata": {
        "id": "j0vEohCzYCuo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dCMmbH2AolsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck3qnXZoLUxp"
      },
      "source": [
        "## `notnull()`: returns list of boolean values indicating whether an item is null or not\n",
        "\n",
        "```\n",
        "data.notnull()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GhUBvx3MoqfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyNNeJbbLUxq"
      },
      "source": [
        "##  `dropna()` With DataFrame objects, things are a bit more complex.  You may want to drop rows or columns that are all NA or only those containing any NAs. `dropna` by default drops any row containing a missing value.\n",
        "\n",
        "```\n",
        "data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA],\n",
        "                     [NA, NA, NA], [NA, 6.5, 3.]])\n",
        "\n",
        "data.dropna()\n",
        "\n",
        "data.dropna(axis=1)\n",
        "\n",
        "data.isnull().sum()\n",
        "\n",
        "data.isnull().sum().sum()\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Run and test the above code."
      ],
      "metadata": {
        "id": "A9Jg8Aj8skLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivh13DVCItVa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn_Tlt_wLUxr"
      },
      "source": [
        "## Passing how='all' will only drop rows that are all NA:\n",
        "\n",
        "```\n",
        "data.dropna(how='all')\n",
        "\n",
        "data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA],\n",
        "                     [NA, NA, NA], [NA, 6.5, 3.]])\n",
        "\n",
        "data[3] = NA\n",
        "\n",
        "data.dropna(axis=1, how='all')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Run and test the above code."
      ],
      "metadata": {
        "id": "Cd-sFHcGYLeE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GkMN8s0hYMrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtslcoI9LUxs"
      },
      "source": [
        "## Suppose you want to keep only rows containing a certain number of observations. You can indicate this with the thresh argument as `dropna(thresh=2)`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oeeZ9hBLUxt"
      },
      "source": [
        "```\n",
        "df = pd.DataFrame(np.random.randn(7, 3))\n",
        "df.iloc[:4, 1] = NA\n",
        "df.iloc[:2, 2] = NA\n",
        "\n",
        "df.dropna()\n",
        "df.dropna(thresh=2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Run and test the above code."
      ],
      "metadata": {
        "id": "jQftty0FYOR0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQYIJMdcpcSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputations\n",
        "\n",
        "![](https://imgur.com/bL0iHde.png)\n",
        "\n",
        ">Imputation refers to replacing missing data with substituted values. There are a lot of ways in which the missing values can be imputed depending upon the nature of the problem and data. Dependng upon the nature of the problem, imputation techniques can be broadly they can be classified as follows:\n",
        "\n",
        "\n",
        "### Basic Imputation Techniques\n",
        "  \n",
        "  - Imputating with a constant value\n",
        "  - Imputation using the statistics (mean, median or most frequent) of each column in which the missing values are located\n",
        "\n",
        "For this we shall use the `The SimpleImputer` class from sklearn."
      ],
      "metadata": {
        "id": "kiQscNzKEHK1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eCZ0CBzLUxv"
      },
      "source": [
        "### Filling In Missing Data\n",
        "For most purposes, the `fillna` method is the workhorse function to use. Calling `fillna` with a constant replaces missing values with that value:\n",
        "\n",
        "```\n",
        "data = pd.DataFrame([[1., 2, 3.], [4., NA, NA],\n",
        "                     [NA, NA, NA], [NA, 8, 9]])\n",
        "\n",
        "\n",
        "data.fillna(0)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9XApfZHLUxw"
      },
      "source": [
        "Calling fillna with a dict, you can use a different fill value for each column:\n",
        "\n",
        "```\n",
        "data.fillna({0: 5, 1: 0.5, 2: 0})\n",
        "\n",
        "data.fillna(data.mean(), inplace = True)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Run and test the above code."
      ],
      "metadata": {
        "id": "OIuZAwjLYRep"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cjPa7kRbYSqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuOLQr3mLUxw"
      },
      "source": [
        "### fillna returns a new object, but you can modify the existing object in-place:\n",
        "\n",
        "```\n",
        "_ = df.fillna(0, inplace=True)\n",
        "\n",
        "df.fillna({1:0.3, 2:0.5}, inplace=True)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Run and test the above code."
      ],
      "metadata": {
        "id": "HbrKTRrCYUeq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-chVfF9iy7c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNRUe-2ULUxy"
      },
      "source": [
        "### With fillna you can do lots of other things with a little creativity. For example, you might pass the mean or median value of a Series:\n",
        "\n",
        "```\n",
        "data = pd.Series([1., NA, 3.5, NA, 7])\n",
        "\n",
        "data.fillna(data.median())\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YKe1PH4SqPS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We can also fill in the missing value using the previous or next value by `ffill` or `bfill`.\n",
        "```\n",
        "df = pd.DataFrame(np.random.randn(6, 3))\n",
        "df.iloc[2:, 1] = NA\n",
        "df.iloc[4:, 2] = NA\n",
        "\n",
        "data.fillna(method='bfill')\n",
        "\n",
        "df.fillna(method='ffill', limit=2)\n",
        "```"
      ],
      "metadata": {
        "id": "0JOo7QqwtYCt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef-QqPFCLUx1"
      },
      "source": [
        "# Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The transform() function:\n",
        "- The transform() function in pandas is used to perform operations on each element of a series or column in a DataFrame.\n",
        "- Unlike apply(), transform() returns an object that is the same size as the input.\n",
        "- This makes it particularly useful for filling missing values.\n",
        "- The transform() function is often used with groupby objects to perform operations within groups while maintaining the original DataFrame shape.\n",
        "```\n",
        "df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', ],\n",
        "                 'B': [1, np.nan, 2, 4, np.nan, 2]})\n",
        "B_imputed = df.groupby('A')['B'].transform(lambda x: x.fillna(x.mean()))\n",
        "```"
      ],
      "metadata": {
        "id": "6SVEjJqzxUwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Run and test the above code."
      ],
      "metadata": {
        "id": "hgSRTgi91BRv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XRp4MeK1FO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ufim2qELUx1"
      },
      "source": [
        "## Removing Duplicates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "data = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'],\n",
        "                     'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "cxR3FZ82t6gE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMG4rDMqLUx1"
      },
      "source": [
        "## The DataFrame method `duplicated()` returns a boolean Series indicating whether each row is a duplicate (has been observed in a previous row) or not:\n",
        "```\n",
        "data.duplicated()\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4OhMakEoqfnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDPHZ_WlLUx2"
      },
      "source": [
        "### drop_duplicates returns a DataFrame where the duplicated array is removed:\n",
        "```\n",
        "data.drop_duplicates()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-90lIEiuqguA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFk5KkiTLUx2"
      },
      "source": [
        "### drop_duplicates can take a column as a parameter.\n",
        "\n",
        "```\n",
        "data['v1'] = range(7)\n",
        "\n",
        "data.drop_duplicates(['k1', 'k2'])\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E4HaVkQiqneH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om77MKhWLUx3"
      },
      "source": [
        "### duplicated and drop_duplicates by default keep the first observed value combination. Passing keep='last' will return the last one:\n",
        "\n",
        "```\n",
        "data.drop_duplicates(['k1', 'k2'], keep='last')\n",
        "\n",
        "data.drop_duplicates(keep='last')\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nm_hYRbqt1de"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5HRvhT0BquKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X3-tvS2LUx3"
      },
      "source": [
        "## Transforming Data Using a Function or Mapping\n",
        "### For many datasets, you may wish to perform some transformation based on the values in an array, Series, or column in a DataFrame. Consider the following data collected about various kinds of meat:\n",
        "\n",
        "```\n",
        "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',\n",
        "                              'Pastrami', 'corned beef', 'Bacon',\n",
        "                              'pastrami', 'honey ham', 'nova lox'],\n",
        "                     'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du3sx9rqLUx4"
      },
      "source": [
        "### Suppose we wanted to add a column indicating the type of animal that each food came from.\n",
        "### Step 1: Write down a mapping of each distinct meat type to the kind of animal:\n",
        "\n",
        "```\n",
        "meat_to_animal = {\n",
        "  'bacon': 'pig',\n",
        "  'pulled pork': 'pig',\n",
        "  'pastrami': 'cow',\n",
        "  'corned beef': 'cow',\n",
        "  'honey ham': 'pig',\n",
        "  'nova lox': 'salmon'\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT6yp_k8LUx4"
      },
      "source": [
        "### Step 2: Normalize the text if the map only uses normalized lower-case strings.\n",
        "\n",
        "```\n",
        "data['food'].str.lower()\n",
        "\n",
        "lowercased = data['food'].str.lower()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzM67Q1qLUx5"
      },
      "source": [
        "### Step 3: Apply the map method on a Series by accepting a function or dict-like object containing a mapping\n",
        "\n",
        "```\n",
        "data['animal'] = data['food'].str.lower().map(meat_to_animal)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrhfSMCKLUx5"
      },
      "source": [
        "## We could also have passed a function that does all the work:\n",
        "```\n",
        "data['food'].map(lambda x: meat_to_animal[x.lower()])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0jTt61cLUx6"
      },
      "source": [
        "# Replacing Values\n",
        "Filling in missing data with the fillna method is a special case of more general value\n",
        "replacement. As you’ve already seen, map can be used to modify a subset of values in\n",
        "an object.\n",
        "## `replace` provides a simpler and more flexible way to do so. Let’s consider this Series:\n",
        "\n",
        "```\n",
        "data = pd.Series([1., -999., 2., -999., -1000., 3.])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A43roNXELUx6"
      },
      "source": [
        "The -999 values might be sentinel values for missing data. To replace these with NA\n",
        "values that pandas understands, we can use replace, producing a new Series (unless\n",
        "you pass inplace=True):\n",
        "\n",
        "```\n",
        "data1 = data.replace([-999, -1000], np.nan)\n",
        "\n",
        "data1.fillna(data1.mean())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Run and test the above code."
      ],
      "metadata": {
        "id": "QyV_6MUTYgOF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SAWJEAl7YhKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z42OKR6WLUx7"
      },
      "source": [
        "If you want to replace multiple values at once, you instead pass a list and then the\n",
        "substitute value:\n",
        "\n",
        "```\n",
        "data.replace([-999, -1000], np.nan)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwANGN2ALUx8"
      },
      "source": [
        "To use a different replacement for each value, pass a list of substitutes:\n",
        "\n",
        "```\n",
        "data.replace([-999, -1000], [np.nan, 0])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IX1YEp7LUx8"
      },
      "source": [
        "The argument passed can also be a dict:\n",
        "\n",
        "```\n",
        "data.replace({-999: np.nan, -1000: 0})\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osEPDUF-LUx9"
      },
      "source": [
        "## Renaming Axis Indexes\n",
        "### Like values in a Series, axis labels can be similarly transformed by a function or mapping of some form to produce new, differently labeled objects.\n",
        "### We can also modify the axes in-place without creating a new data structure. Here’s a simple example:\n",
        "\n",
        "```\n",
        "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
        "                    index=['Ohio', 'Colorado', 'New York'],\n",
        "                    columns=['one', 'two', 'three', 'four'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJmaNbtnLUx-"
      },
      "source": [
        "### We can modify the index of the DataFrame in-place:\n",
        "\n",
        "```\n",
        "transform = lambda x: x[:4].upper()\n",
        "data.index = data.index.map(transform)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwXDdoIzLUx_"
      },
      "source": [
        "### If we want to create a transformed version of a dataset without modifying the original, a useful method is rename:\n",
        "\n",
        "```\n",
        "data.rename(index=str.title, columns=str.upper)\n",
        "\n",
        "data.rename(columns={\"one\":'column1'})\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWtfjmczLUx_"
      },
      "source": [
        "### Notably, rename can be used in conjunction with a dict-like object providing new values for a subset of the axis labels:\n",
        "\n",
        "```\n",
        "data.rename(index={'OHIO': 'INDIANA'},\n",
        "            columns={'three': 'peekaboo'})\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPmuWH9MLUyA"
      },
      "source": [
        "### rename saves you from the chore of copying the DataFrame manually and assigning to its index and columns attributes. Should you wish to modify a dataset in-place, pass inplace=True:\n",
        "\n",
        "```\n",
        "data.rename(index={'OHIO': 'INDIANA'}, inplace=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCQTSXE8FXkB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}