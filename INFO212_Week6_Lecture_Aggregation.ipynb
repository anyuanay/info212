{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anyuanay/info212/blob/main/INFO212_Week6_Lecture_Aggregation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP36VkAKUfws"
      },
      "source": [
        "# INFO 212: Data Science Programming 1\n",
        "___\n",
        "\n",
        "## Week 6: Lecture: Data Aggregation and Group Operations\n",
        "---\n",
        "\n",
        "**Agenda:**\n",
        "- frame.groupby(list).agg\n",
        "- groupby by a function\n",
        "- groupby by a dictionary\n",
        "- groupby by a list\n",
        "- iterate over groups\n",
        "- split-apply-combine\n",
        "- pivotal tables and cross-tabulation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StAfgnGZUfwz"
      },
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MryFbQ2LUfw1"
      },
      "source": [
        "# GroupBy Mechanics\n",
        "\n",
        "Categorizing a dataset and applying a function to each group, whether an aggregation\n",
        "or transformation, is often a critical component of a data analysis workflow. After\n",
        "loading, merging, and preparing a dataset, you may need to compute group statistics\n",
        "or possibly pivot tables for reporting or visualization purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnoymTcOUfw1"
      },
      "source": [
        "## The split-apply-combine Principle for GroupBy\n",
        "In the first stage of the groupby process, data contained in a pandas object, whether a Series, Data‐\n",
        "Frame, or otherwise, is split into groups based on one or more keys that you provide.\n",
        "The splitting is performed on a particular axis of an object. For example, a DataFrame\n",
        "can be grouped on its rows (axis=0) or its columns (axis=1). Once this is done, a\n",
        "function is applied to each group, producing a new value. Finally, the results of all\n",
        "those function applications are combined into a result object. The form of the resulting\n",
        "object will usually depend on what’s being done to the data.\n",
        "\n",
        "![](https://i.imgur.com/89PD9om.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi78t1ScUfw2"
      },
      "source": [
        "## pandas provides a flexible groupby interface, enabling you to slice, dice, and summarize datasets in a natural way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waAdH0D4Ufw2"
      },
      "source": [
        "## Each grouping key can take many forms, and the keys do not have to be all of the same type:\n",
        "- A list or array of values that is the same length as the axis being grouped\n",
        "- A value indicating a column name in a DataFrame\n",
        "- A dict or Series giving a correspondence between the values on the axis being\n",
        "grouped and the group names\n",
        "- A function to be invoked on the axis index or the individual labels in the index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame example:\n",
        "\n",
        "```\n",
        "df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
        "                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
        "                   'data1' : np.random.randn(5),\n",
        "                   'data2' : np.random.randn(5)})\n",
        "\n",
        "df.info()\n",
        "```"
      ],
      "metadata": {
        "id": "cDdi_Lr6w0Of"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EJr-TKhUfw9"
      },
      "source": [
        "## Frequently, the grouping information is found in the same DataFrame as the data you want to work on. In that case, you can pass column names (whether those are strings, numbers, or other Python objects) as the group keys:\n",
        "```\n",
        "df.groupby('key1')[['data1', 'data2']].mean()\n",
        "\n",
        "df.groupby('key1')\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Compute the average total_bill and tip_pct for each unique value in the day column."
      ],
      "metadata": {
        "id": "N0Z30WZf_NXe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hsk76PSzgURt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD_S5pjyUfw6"
      },
      "source": [
        "## The group keys could be any arrays of the right length:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "states = np.array(['Ohio', 'California', 'California', 'Ohio', 'Ohio'])\n",
        "years = np.array([2005, 2005, 2006, 2005, 2006])\n",
        "\n",
        "\n",
        "df['data1'].groupby(states).mean()\n",
        "\n",
        "df['data2'].groupby(years).sum()\n",
        "\n",
        "df.groupby([states, years]).mean()\n",
        "```"
      ],
      "metadata": {
        "id": "7wbHvAJQxvi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataSet: Meals and Tips\n",
        "Download the `tips.csv` dataset and load it as a DataFrame here."
      ],
      "metadata": {
        "id": "JRpIaC4C9qad"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fy68lYb3gG1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore the tips dataset"
      ],
      "metadata": {
        "id": "IRuQF3Vj-LoA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qn8RkHWWgIoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add a tip_pct column\n",
        "Compute the percentage of tips for each meal"
      ],
      "metadata": {
        "id": "I9uT9N5V-ZpT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dOLkPP6rgKJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Extract the column `time` as a list called `meal_type`. Compute the maximum total_bill, tip, and tip_pct of each type of meal."
      ],
      "metadata": {
        "id": "HDYrK-Wu__e_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTEpwGskgYyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Group by the tips data using the combinations of days and smoker types. Sort the results by the maximums of tip_pct in descending order."
      ],
      "metadata": {
        "id": "UfWxaaNQCluo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmsDvqHtgi_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_l-BJwRUfw-"
      },
      "source": [
        "# Iterating Over Groups\n",
        "## The GroupBy object supports iteration, generating a sequence of 2-tuples containing the group name along with the chunk of data. Consider the following:\n",
        "```\n",
        "for key, group in df.groupby('key1'):\n",
        "    print(key)\n",
        "    print(group)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH3QMVvBUfw_"
      },
      "source": [
        "## In the case of multiple keys, the first element in the tuple will be a tuple of key values:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "for key, chunk in df.groupby(['key1', 'key2']):\n",
        "    print(key[0], key[1])\n",
        "    print(chunk)\n",
        "```"
      ],
      "metadata": {
        "id": "BRAILoBApBUP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4pk4gAXUfxD"
      },
      "source": [
        "## Of course, you can choose to do whatever you want with the pieces of data. A recipe you may find useful is computing a dict of the data pieces as a one-liner:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "pieces = dict(list(df.groupby('key1')))\n",
        "for k in pieces:\n",
        "    print('key = ', k)\n",
        "    print('chunk =\\n', pieces[k])\n",
        "\n",
        "\n",
        "pieces['b']\n",
        "```"
      ],
      "metadata": {
        "id": "_IVAwwqNpJKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Group by the tips dataset by the unique values in day column;  sort the all Sunday's records by the sizes in descending order."
      ],
      "metadata": {
        "id": "svNsSY3RDieO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wM2mzauNg2oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqUGwoP6UfxE"
      },
      "source": [
        "## By default, groupby groups on axis=0, but you can group on any of the other axes. For example, we could group the columns of our example df here by dtype like so:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "grouped = df.groupby(df.dtypes, axis=1)\n",
        "\n",
        "\n",
        "for dtype, group in grouped:\n",
        "    print(dtype)\n",
        "    print(group)\n",
        "```"
      ],
      "metadata": {
        "id": "5dnoEr0ipiCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Group by the tips dataset on the data types of the columns."
      ],
      "metadata": {
        "id": "MfmLWMF5JKzx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VVbHSfUog6NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_PiiUNaUfxH"
      },
      "source": [
        "# How to Group by Two Consecutive Rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "df = pd.DataFrame([1, 2, 3, 4, 1, 2,3], columns=['val'])\n",
        "\n",
        "for key, data in df.groupby((np.arange(len(df)) // 3)):\n",
        "    print(key)\n",
        "    print(data)\n",
        "```"
      ],
      "metadata": {
        "id": "Vrl6tq68qNDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Group by the tips dataset by every 4 consecutive rows."
      ],
      "metadata": {
        "id": "QbOArpQgKl7f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvfzGsZag9d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZlwl_sPUfxJ"
      },
      "source": [
        "# Grouping with Dicts and Series\n",
        "## Grouping information may exist in a form other than an array. Let’s consider another example DataFrame:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "people = pd.DataFrame(np.random.randn(5, 5),\n",
        "                      columns=['a', 'b', 'c', 'd', 'e'],\n",
        "                      index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])\n",
        "people.iloc[2:3, [1, 2]] = np.nan # Add a few NA values\n",
        "people\n",
        "```"
      ],
      "metadata": {
        "id": "j4TK_sg-qXwO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA2lttN4UfxJ"
      },
      "source": [
        "## Now, suppose I have a group correspondence for the columns and want to sum together the columns by group:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "mapping = {'a': 'red', 'b': 'red', 'c': 'blue',\n",
        "           'd': 'blue', 'e': 'red', 'f' : 'orange'}\n",
        "```"
      ],
      "metadata": {
        "id": "onYnTZhKqafy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmhg5BsPUfxJ"
      },
      "source": [
        "## Now, you could construct an array from this dict to pass to groupby, but instead we can just pass the dict:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "by_column = people.groupby(mapping, axis=1)\n",
        "by_column.sum()\n",
        "```"
      ],
      "metadata": {
        "id": "VA2-kwp2qhMb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je8F26QuUfxK"
      },
      "source": [
        "## The same functionality holds for Series, which can be viewed as a fixed-size mapping:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "map_series = pd.Series(mapping)\n",
        "map_series\n",
        "\n",
        "\n",
        "people.groupby(map_series, axis=1).sum()\n",
        "```"
      ],
      "metadata": {
        "id": "vILqWiwZqj51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "For the day column, map 'Sun' and 'Sat' to 'weekend' and 'Thur' and 'Fri' to weekday. Compute the mean total_bill and tip_pct of weekend and weekday."
      ],
      "metadata": {
        "id": "w3qPqMV0MIFb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZaWTNknhkce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGYyTgcZUfxL"
      },
      "source": [
        "# Grouping with Functions\n",
        "Using Python functions is a more generic way of defining a group mapping compared\n",
        "with a dict or Series. Any function passed as a group key will be called once per index\n",
        "value, with the return values being used as the group names. More concretely, consider\n",
        "the example DataFrame above, which has people’s first\n",
        "names as index values. Suppose you wanted to group by the length of the names;\n",
        "while you could compute an array of string lengths, it’s simpler to just pass the len\n",
        "function:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "for k, chunk in people.groupby(len):\n",
        "    print(k)\n",
        "    print(chunk)\n",
        "```"
      ],
      "metadata": {
        "id": "10fhuYJKqsea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Define a function that converts the tip_pct to percentage (100%) and round the percentage to the nearest number multiplied by 10 (i.e, 10, 20, 30, ...). For each rounded percentage, compute the average total_bill and tip_pct."
      ],
      "metadata": {
        "id": "DC4V_6KuTWlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHeRR_hWhqkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWvNebtZUfxM"
      },
      "source": [
        "# Grouping by Index Levels\n",
        "## A convenience for hierarchically indexed datasets is the ability to aggregate using one of the levels of an axis index. Let’s look at an example:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "columns = pd.MultiIndex.from_arrays([['US', 'US', 'US', 'JP', 'JP'],\n",
        "                                    [1, 3, 5, 1, 3]],\n",
        "                                    names=['cty', 'tenor'])\n",
        "hier_df = pd.DataFrame(np.random.randn(4, 5), columns=columns)\n",
        "hier_df\n",
        "```"
      ],
      "metadata": {
        "id": "_6Ro79aYqwXy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ktd2AUYKUfxN"
      },
      "source": [
        "## To group by level, pass the level number or name using the level keyword:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "hier_df.groupby(level='cty', axis=1).count()\n",
        "```"
      ],
      "metadata": {
        "id": "EZklXlgMq0OT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmSScDr4UfxO"
      },
      "source": [
        "# Data Aggregation\n",
        "Aggregations refer to any data transformation that produces scalar values from\n",
        "arrays. The preceding examples have used several of them, including mean, count,\n",
        "min, and sum. However, you are not limited to only this set of\n",
        "methods."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
        "                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
        "                   'data1' : np.random.randn(5),\n",
        "                   'data2' : np.random.randn(5)})\n",
        "df\n",
        "```"
      ],
      "metadata": {
        "id": "c7xh0qsXrAYt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNF1KIKxUfxO"
      },
      "source": [
        "You can use aggregations of your own devising and additionally call any method that\n",
        "is also defined on the grouped object. For example, you might recall that quantile\n",
        "computes sample quantiles of a Series or a DataFrame’s columns.\n",
        "While quantile is not explicitly implemented for GroupBy, it is a Series method and\n",
        "thus available for use. Internally, GroupBy efficiently slices up the Series, calls\n",
        "piece.quantile(0.9) for each piece, and then assembles those results together into\n",
        "the result object:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "grouped = df.groupby('key1')\n",
        "grouped['data1'].quantile(0.9)\n",
        "```"
      ],
      "metadata": {
        "id": "WKBScBsprEF3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYhTGG2DUfxP"
      },
      "source": [
        "## To use your own aggregation functions, pass any function that aggregates an array to the aggregate or agg method:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "def peak_to_peak(arr):\n",
        "    return arr.max() - arr.min()\n",
        "\n",
        "df[['data1', 'data2']].apply(peak_to_peak)\n",
        "\n",
        "df.groupby('key1').agg(peak_to_peak)\n",
        "```"
      ],
      "metadata": {
        "id": "r82uRrg3rIeA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_am9G1T3UfxP"
      },
      "source": [
        "## You may notice that some methods like describe also work, even though they are not aggregations, strictly speaking:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "df.describe()\n",
        "\n",
        "grouped.describe()\n",
        "```"
      ],
      "metadata": {
        "id": "QnYz7lA0rWJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "For each unique value in the day column, compute the maximum, mininum, and the difference between the max and min for total_bill and tip_pct."
      ],
      "metadata": {
        "id": "yeFmENT2ZUWm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1qiUme-hvS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r1OHYpXUfxS"
      },
      "source": [
        "## Select Top Results on Aggregation\n",
        "Suppose we wanted to select the top five tip_pct values by group. First, write a function that selects the rows with the largest values in a particular column:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "def top(df, n=5, column='tip_pct'):\n",
        "    return df.sort_values(by=column, ascending=False)[:n]\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "VEBtfvYpwIUJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4WukWDaUfxT"
      },
      "source": [
        "Now, if we group by smoker, say, and call apply with this function, we get the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "tips.groupby('smoker').apply(top)\n",
        "```"
      ],
      "metadata": {
        "id": "V4avGZrDwq6Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeNox_b_UfxU"
      },
      "source": [
        "The top function is called on each row group from the\n",
        "DataFrame, and then the results are glued together using pandas.concat, labeling the\n",
        "pieces with the group names. The result therefore has a hierarchical index whose\n",
        "inner level contains index values from the original DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "For each unique value in the day column, extract the top 3 total bills."
      ],
      "metadata": {
        "id": "RhS87lqPbWVp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41RRE88Qhy-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hEqOzx2UfxV"
      },
      "source": [
        "In the preceding examples, you see that the resulting object has a hierarchical index formed from the group keys along with the indexes of each piece of the original object. You can disable this by passing group_keys=False to groupby:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "tips.groupby('smoker', group_keys=False).apply(top)\n",
        "```"
      ],
      "metadata": {
        "id": "E0-7euYqxER6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A02lIrfuUfxV"
      },
      "source": [
        "# What is a Pivot Table and How to Use It?\n",
        "- A pivot table is a data summarization tool frequently found in spreadsheet programs\n",
        "and other data analysis software.\n",
        "- It aggregates a table of data by one or more keys,\n",
        "arranging the data in a rectangle with some of the group keys along the rows and\n",
        "some along the columns.\n",
        "- Pivot tables in Python with pandas are made possible\n",
        "through the groupby facility combined with reshape operations\n",
        "utilizing hierarchical indexing.\n",
        "- DataFrame has a pivot_table method, and\n",
        "there is also a top-level pandas.pivot_table function.\n",
        "- In addition to providing a\n",
        "convenience interface to groupby, pivot_table can add partial totals, also known as\n",
        "margins.\n",
        "\n",
        "## Returning to the `tips` dataset, suppose you wanted to compute a table of group means (the default pivot_table aggregation type) arranged by day and smoker on the rows:\n",
        "```\n",
        "tips[['day', 'smoker', 'total_bill', 'tip']].pivot_table(index=['day', 'smoker']).mean()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C-KrrmSUfxX"
      },
      "source": [
        "## This could have been produced with groupby directly. Now, suppose we want to aggregate only tip_pct and size, and additionally group by time. I’ll put smoker in the table columns and day in the rows:\n",
        "```\n",
        "tips.pivot_table(['tip_pct', 'size'], index=['time', 'day'],\n",
        "                 columns='smoker')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHE5v3DUUfxX"
      },
      "source": [
        "## We could augment this table to include partial totals by passing margins=True. This has the effect of adding All row and column labels, with corresponding values being the group statistics for all the data within a single tier:\n",
        "```\n",
        "tips.pivot_table(['size', 'tip_pct'], index=['time', 'day'],\n",
        "                 columns='smoker', margins=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEeHSIOCUfxY"
      },
      "source": [
        "## Here, the All values are means without taking into account smoker versus nonsmoker (the All columns) or any of the two levels of grouping on the rows (the All row).\n",
        "\n",
        "## To use a different aggregation function, pass it to aggfunc. For example, 'count' or len will give you a cross-tabulation (count or frequency) of group sizes:\n",
        "```\n",
        "tips.pivot_table('tip_pct', index=['time', 'smoker'], columns='day',\n",
        "                 aggfunc=len, margins=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ25tq3WUfxY"
      },
      "source": [
        "## If some combinations are empty (or otherwise NA), you may wish to pass a fill_value:\n",
        "```\n",
        "tips.pivot_table('tip_pct', index=['time', 'size', 'smoker'],\n",
        "                 columns='day', aggfunc='mean', fill_value=0)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PIfY2QGUfxZ"
      },
      "source": [
        "# What is Cross-Tabulation? How to Use Crosstab?\n",
        "## A cross-tabulation (or crosstab for short) is a special case of a pivot table that computes group frequencies. Here is an example:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "data = \"\"\"\\\n",
        "Sample  Nationality  Handedness\n",
        "1   USA  Right-handed\n",
        "2   Japan    Left-handed\n",
        "3   USA  Right-handed\n",
        "4   Japan    Right-handed\n",
        "5   Japan    Left-handed\n",
        "6   Japan    Right-handed\n",
        "7   USA  Right-handed\n",
        "8   USA  Left-handed\n",
        "9   Japan    Right-handed\n",
        "10  USA  Right-handed\"\"\"\n",
        "data = pd.read_table(StringIO(data), sep='\\s+')\n",
        "```"
      ],
      "metadata": {
        "id": "9mrs6c27x4tK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkyxZPBVUfxa"
      },
      "source": [
        "## As part of some survey analysis, we might want to summarize this data by nationality and handedness. You could use pivot_table to do this, but the pandas.crosstab function can be more convenient:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "pd.crosstab(data.Nationality, data.Handedness, margins=True)\n",
        "```"
      ],
      "metadata": {
        "id": "pGctjWrtx-DI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgJToIhdUfxa"
      },
      "source": [
        "## The first two arguments to crosstab can each either be an array or Series or a list of arrays. As in the tips data:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "pd.crosstab([tips.time, tips.day], tips.smoker, margins=True).plot.bar()\n",
        "```"
      ],
      "metadata": {
        "id": "dI_EvgSQyCpY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz1BO1TkUfxb"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}